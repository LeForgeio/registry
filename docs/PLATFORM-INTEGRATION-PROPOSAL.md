# LeForge Plugin Integration Proposal
## Making Plugins Easy to Use Across Low-Code/No-Code Platforms

This document outlines the strategy and deliverables needed to make LeForge plugins easily consumable by major workflow automation and low-code platforms.

---

## Executive Summary

Each platform has its own integration mechanism, but they share a common thread: **OpenAPI/Swagger specifications** are the universal language. Our strategy:

1. **Generate platform-optimized OpenAPI specs** from each plugin
2. **Create platform-specific packages** where OpenAPI isn't sufficient
3. **Provide ready-to-import connectors** for each platform

---

## Platform Integration Matrix

| Platform | Integration Type | Primary Format | Auth Support | Effort |
|----------|------------------|----------------|--------------|--------|
| **Nintex Workflow Cloud** | Xtensions | OpenAPI 2.0 (Swagger) | API Key, OAuth2, Basic | Low |
| **Nintex K2** | REST Service Broker + SmartObjects | Swagger 2.0 | API Key, OAuth, Static | Medium |
| **n8n** | Custom Nodes (TypeScript) | npm package | Credentials system | High |
| **Power Automate** | Custom Connectors | OpenAPI 2.0/3.0 | API Key, OAuth2 | Low |
| **OutSystems** | REST Integration + Forge Component | OpenAPI/WSDL | API Key, OAuth2 | Medium |
| **Mendix** | Marketplace Module | REST + Microflow Actions | API Key, OAuth2 | High |
| **Salesforce** | External Services + Flow Actions | OpenAPI 3.0 + Apex | OAuth 2.0, Named Credentials | Medium |
| **ServiceNow** | IntegrationHub Spokes + Flow Designer | REST API Actions | OAuth 2.0, API Key | Medium |

---

## 1. Nintex Workflow Cloud (Xtensions)

### What We Need to Create
**OpenAPI 2.0 Specification files** (one per plugin) with:
- Proper security definitions (API Key in header)
- Well-defined request/response schemas
- Action-oriented operation IDs
- Rich descriptions for UI generation

### Deliverables
```
/integrations/nintex-cloud/
â”œâ”€â”€ llm-service.swagger.json
â”œâ”€â”€ formula-engine.swagger.json
â”œâ”€â”€ streaming-file-service.swagger.json
â”œâ”€â”€ crypto-service.swagger.json
â”œâ”€â”€ icons/
â”‚   â”œâ”€â”€ llm-service.png (64x64)
â”‚   â”œâ”€â”€ formula-engine.png
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md (installation guide)
```

### Implementation
```json
{
  "swagger": "2.0",
  "info": {
    "title": "LeForge LLM Service",
    "description": "AI-powered text generation, chat, and analysis",
    "version": "2.0.0"
  },
  "host": "{{your-domain}}/api/v1",
  "schemes": ["https"],
  "securityDefinitions": {
    "api_key": {
      "type": "apiKey",
      "in": "header",
      "name": "X-API-Key"
    }
  },
  "paths": {
    "/chat": {
      "post": {
        "operationId": "SendChatMessage",
        "summary": "Send a chat message and get AI response",
        "x-ntx-summary": "Chat with AI",
        // ... full endpoint definition
      }
    }
  }
}
```

### User Experience
1. Admin uploads `.swagger.json` to Nintex Xtensions
2. Configures API key connection
3. Actions appear in workflow designer
4. Drag-and-drop to use

---

## 2. Nintex K2 (SmartObjects + Service Broker)

### What We Need to Create
**Swagger files + SmartObject templates** for K2's REST Service Broker

### Deliverables
```
/integrations/nintex-k2/
â”œâ”€â”€ swagger/
â”‚   â”œâ”€â”€ llm-service.json
â”‚   â”œâ”€â”€ formula-engine.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ smartobject-templates/
â”‚   â”œâ”€â”€ LLM_ChatCompletion.xml
â”‚   â”œâ”€â”€ LLM_TextGeneration.xml
â”‚   â””â”€â”€ ...
â””â”€â”€ deployment-guide.md
```

### Implementation Notes
- K2 requires Swagger 2.0 format
- SmartObjects provide the UI abstraction
- Service Broker connects REST to SmartObjects
- Support OAuth and API Key authentication

### Key Features for K2
- **SmartObject Methods**: Create, Read, Execute operations
- **Complex Object Handling**: Serialize/deserialize JSON properly
- **Form Integration**: SmartObjects can bind to K2 Forms

---

## 3. n8n (Custom Nodes)

### What We Need to Create
**TypeScript npm packages** following n8n node structure

### Deliverables
```
/integrations/n8n/
â”œâ”€â”€ n8n-nodes-LeForge/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ LeForgeLLM/
â”‚   â”‚   â”‚   â”œâ”€â”€ LeForgeLLM.node.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ LeForgeLLM.node.json
â”‚   â”‚   â”‚   â””â”€â”€ LeForge-llm.svg
â”‚   â”‚   â”œâ”€â”€ LeForgeFormula/
â”‚   â”‚   â”‚   â”œâ”€â”€ LeForgeFormula.node.ts
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ LeForgeFiles/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ credentials/
â”‚   â”‚   â””â”€â”€ LeForgeApi.credentials.ts
â”‚   â””â”€â”€ README.md
â””â”€â”€ publish-guide.md
```

### Implementation Example
```typescript
// LeForgeLLM.node.ts
import {
  INodeType,
  INodeTypeDescription,
  IExecuteFunctions,
  INodeExecutionData,
} from 'n8n-workflow';

export class LeForgeLLM implements INodeType {
  description: INodeTypeDescription = {
    displayName: 'LeForge LLM',
    name: 'LeForgeLlm',
    icon: 'file:LeForge-llm.svg',
    group: ['transform'],
    version: 1,
    subtitle: '={{$parameter["operation"]}}',
    description: 'AI text generation, chat, and analysis',
    defaults: {
      name: 'LeForge LLM',
    },
    inputs: ['main'],
    outputs: ['main'],
    credentials: [
      {
        name: 'LeForgeApi',
        required: true,
      },
    ],
    properties: [
      {
        displayName: 'Operation',
        name: 'operation',
        type: 'options',
        noDataExpression: true,
        options: [
          { name: 'Chat', value: 'chat' },
          { name: 'Generate Text', value: 'generate' },
          { name: 'Summarize', value: 'summarize' },
          { name: 'Classify', value: 'classify' },
          { name: 'Extract Entities', value: 'extract' },
        ],
        default: 'chat',
      },
      // ... more properties per operation
    ],
  };

  async execute(this: IExecuteFunctions): Promise<INodeExecutionData[][]> {
    // Implementation
  }
}
```

### Distribution
- Publish to npm: `npm publish`
- Users install: `npm install n8n-nodes-LeForge`
- Or submit to n8n Community Nodes

---

## 4. Microsoft Power Automate

### What We Need to Create
**Custom Connector packages** (OpenAPI + icons + apiProperties.json)

### Deliverables
```
/integrations/power-automate/
â”œâ”€â”€ LeForge-LLM/
â”‚   â”œâ”€â”€ apiDefinition.swagger.json
â”‚   â”œâ”€â”€ apiProperties.json
â”‚   â”œâ”€â”€ icon.png (32x32)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ LeForge-Formula/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ LeForge-Files/
â”‚   â””â”€â”€ ...
â””â”€â”€ deployment-guide.md
```

### Implementation
```json
// apiProperties.json
{
  "properties": {
    "connectionParameters": {
      "api_key": {
        "type": "securestring",
        "uiDefinition": {
          "displayName": "API Key",
          "description": "LeForge API Key",
          "tooltip": "Provide your LeForge API Key",
          "constraints": {
            "required": "true"
          }
        }
      }
    },
    "iconBrandColor": "#6366f1",
    "capabilities": [],
    "policyTemplateInstances": []
  }
}
```

### Key Features for Power Automate
- **Triggers**: Webhook-based triggers for events
- **Actions**: All plugin operations as actions
- **Dynamic Schema**: Response schemas for downstream use
- **Pagination**: Handle large result sets

### Certification Path
1. Create and test custom connector
2. Submit for Microsoft certification
3. Appear in public connector gallery

---

## 5. OutSystems

### What We Need to Create
**Forge Components** (OutSystems modules) + REST API definitions

### Deliverables
```
/integrations/outsystems/
â”œâ”€â”€ LeForge_LLM/
â”‚   â”œâ”€â”€ LeForge_LLM.oml        # OutSystems Module
â”‚   â”œâ”€â”€ documentation/
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ resources/
â”‚       â””â”€â”€ icon.png
â”œâ”€â”€ LeForge_Formula/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ LeForge_Files/
â”‚   â””â”€â”€ ...
â””â”€â”€ REST-API-Specs/
    â”œâ”€â”€ llm-service.json
    â””â”€â”€ ...
```

### Implementation Approach
1. **Create Service Studio Module**
   - Define REST API consumption
   - Create Server Actions wrapping each endpoint
   - Build reusable UI blocks (optional)
   
2. **Expose as Forge Component**
   - Package module with documentation
   - Publish to OutSystems Forge

### Server Action Example
```
// In OutSystems Service Studio
ServerAction: LLM_Chat
  Input: 
    - Message (Text)
    - SystemPrompt (Text, optional)
    - MaxTokens (Integer, default=512)
  Output:
    - Response (Text)
    - Success (Boolean)
    - ErrorMessage (Text)
  
  Logic:
    1. Call REST API (POST /api/v1/chat)
    2. Parse JSON response
    3. Return results
```

---

## 6. Mendix

### What We Need to Create
**Mendix Marketplace Modules** with Java actions and microflow activities

### Deliverables
```
/integrations/mendix/
â”œâ”€â”€ LeForgeLLM/
â”‚   â”œâ”€â”€ module/
â”‚   â”‚   â”œâ”€â”€ LeForgeLLM.mpk
â”‚   â”‚   â”œâ”€â”€ javasource/
â”‚   â”‚   â”‚   â””â”€â”€ LeForge/
â”‚   â”‚   â”‚       â””â”€â”€ actions/
â”‚   â”‚   â”œâ”€â”€ microflows/
â”‚   â”‚   â””â”€â”€ pages/ (optional demo pages)
â”‚   â”œâ”€â”€ documentation/
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ test-app/
â”œâ”€â”€ LeForgeFormula/
â”‚   â””â”€â”€ ...
â””â”€â”€ LeForgeFiles/
    â””â”€â”€ ...
```

### Implementation Approach
1. **REST API Integration**
   - Use Mendix's Consume REST Service feature
   - Map endpoints to domain model
   
2. **Java Actions** (for complex operations)
   ```java
   // Chat.java
   public class Chat extends CustomJavaAction<String> {
       private String message;
       private String systemPrompt;
       
       @Override
       public String executeAction() throws Exception {
           // Call LeForge API
           return response;
       }
   }
   ```

3. **Microflow Activities**
   - Expose Java actions as toolbox items
   - Create helper microflows for common patterns

### Distribution
- Export as .mpk module
- Publish to Mendix Marketplace
- Users import directly into Studio Pro

---

## 7. Salesforce (External Services + Flow Actions)

### What We Need to Create
**External Services definitions** (OpenAPI 3.0) + **Apex wrapper classes** + **Flow-compatible invocable actions**

### Deliverables
```
/integrations/salesforce/
â”œâ”€â”€ external-services/
â”‚   â”œâ”€â”€ LeForge_LLM.yaml           # OpenAPI 3.0 spec
â”‚   â”œâ”€â”€ LeForge_Formula.yaml
â”‚   â”œâ”€â”€ LeForge_Files.yaml
â”‚   â””â”€â”€ LeForge_Crypto.yaml
â”œâ”€â”€ apex/
â”‚   â”œâ”€â”€ classes/
â”‚   â”‚   â”œâ”€â”€ LeForgeLLMService.cls
â”‚   â”‚   â”œâ”€â”€ LeForgeLLMService.cls-meta.xml
â”‚   â”‚   â”œâ”€â”€ LeForgeFormulaService.cls
â”‚   â”‚   â”œâ”€â”€ LeForgeCryptoService.cls
â”‚   â”‚   â””â”€â”€ LeForgeFileService.cls
â”‚   â”œâ”€â”€ namedCredentials/
â”‚   â”‚   â””â”€â”€ LeForge_API.namedCredential-meta.xml
â”‚   â””â”€â”€ externalServiceRegistrations/
â”‚       â””â”€â”€ LeForge_LLM.externalServiceRegistration-meta.xml
â”œâ”€â”€ package/
â”‚   â””â”€â”€ package.xml                  # Deployable metadata package
â””â”€â”€ README.md
```

### Implementation Approach

#### Option A: External Services (Recommended for simplicity)
Salesforce can consume OpenAPI 3.0 specs directly via External Services:

```yaml
# LeForge_LLM.yaml (OpenAPI 3.0 for Salesforce)
openapi: "3.0.0"
info:
  title: LeForge LLM Service
  version: "2.0.0"
servers:
  - url: https://your-LeForge-instance.com/api/v1
paths:
  /chat:
    post:
      operationId: sendChatMessage
      summary: Send a chat message and get AI response
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                message:
                  type: string
                system_prompt:
                  type: string
                max_tokens:
                  type: integer
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  response:
                    type: string
                  tokens_used:
                    type: integer
```

#### Option B: Apex Invocable Actions (For complex logic)
```java
// LeForgeLLMService.cls
public class LeForgeLLMService {
    
    @InvocableMethod(label='Chat with AI' description='Send a message to LeForge LLM and get a response' category='LeForge')
    public static List<ChatResponse> chat(List<ChatRequest> requests) {
        List<ChatResponse> responses = new List<ChatResponse>();
        
        for (ChatRequest req : requests) {
            HttpRequest httpReq = new HttpRequest();
            httpReq.setEndpoint('callout:LeForge_API/chat');
            httpReq.setMethod('POST');
            httpReq.setHeader('Content-Type', 'application/json');
            httpReq.setBody(JSON.serialize(new Map<String, Object>{
                'message' => req.message,
                'system_prompt' => req.systemPrompt,
                'max_tokens' => req.maxTokens
            }));
            
            Http http = new Http();
            HttpResponse httpRes = http.send(httpReq);
            
            ChatResponse res = new ChatResponse();
            if (httpRes.getStatusCode() == 200) {
                Map<String, Object> body = (Map<String, Object>) JSON.deserializeUntyped(httpRes.getBody());
                res.response = (String) body.get('response');
                res.tokensUsed = (Integer) body.get('tokens_used');
                res.success = true;
            } else {
                res.success = false;
                res.errorMessage = httpRes.getBody();
            }
            responses.add(res);
        }
        return responses;
    }
    
    public class ChatRequest {
        @InvocableVariable(label='Message' required=true)
        public String message;
        
        @InvocableVariable(label='System Prompt')
        public String systemPrompt;
        
        @InvocableVariable(label='Max Tokens')
        public Integer maxTokens;
    }
    
    public class ChatResponse {
        @InvocableVariable(label='AI Response')
        public String response;
        
        @InvocableVariable(label='Tokens Used')
        public Integer tokensUsed;
        
        @InvocableVariable(label='Success')
        public Boolean success;
        
        @InvocableVariable(label='Error Message')
        public String errorMessage;
    }
}
```

### Named Credential Setup
```xml
<!-- LeForge_API.namedCredential-meta.xml -->
<?xml version="1.0" encoding="UTF-8"?>
<NamedCredential xmlns="http://soap.sforce.com/2006/04/metadata">
    <fullName>LeForge_API</fullName>
    <label>LeForge API</label>
    <endpoint>https://your-LeForge-instance.com/api/v1</endpoint>
    <principalType>NamedUser</principalType>
    <protocol>Custom</protocol>
    <customHeaders>
        <name>X-API-Key</name>
        <value>{!$Credential.LeForge_API.ApiKey}</value>
    </customHeaders>
</NamedCredential>
```

### User Experience in Salesforce Flow
1. Admin imports External Service or deploys Apex package
2. Configure Named Credential with API endpoint and key
3. Actions appear in Flow Builder under "LeForge" category
4. Drag actions into Screen Flows, Record-Triggered Flows, etc.

### Key Features for Salesforce
- **Flow Builder Integration**: Native actions in Flow Builder
- **Apex Callouts**: For complex integrations or triggers
- **Named Credentials**: Secure credential management
- **Platform Events**: Potential for async/streaming patterns
- **AppExchange**: Distribution via managed package

---

## 8. ServiceNow (IntegrationHub Spokes + Flow Designer)

### What We Need to Create
**IntegrationHub Spoke** with Flow Designer actions + REST message configurations

### Deliverables
```
/integrations/servicenow/
â”œâ”€â”€ spoke/
â”‚   â”œâ”€â”€ LeForge_Spoke/
â”‚   â”‚   â”œâ”€â”€ sys_hub_spoke.xml
â”‚   â”‚   â”œâ”€â”€ actions/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_chat.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_generate.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_summarize.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ formula_evaluate.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ crypto_encrypt.xml
â”‚   â”‚   â”‚   â”œâ”€â”€ crypto_decrypt.xml
â”‚   â”‚   â”‚   â””â”€â”€ file_upload.xml
â”‚   â”‚   â”œâ”€â”€ connection_alias/
â”‚   â”‚   â”‚   â””â”€â”€ LeForge_connection.xml
â”‚   â”‚   â””â”€â”€ rest_messages/
â”‚   â”‚       â”œâ”€â”€ LeForge_LLM.xml
â”‚   â”‚       â”œâ”€â”€ LeForge_Formula.xml
â”‚   â”‚       â””â”€â”€ LeForge_Crypto.xml
â”‚   â””â”€â”€ update_set.xml               # Deployable update set
â”œâ”€â”€ scripted-rest/
â”‚   â””â”€â”€ LeForgeWebhook.js          # For async callbacks
â”œâ”€â”€ documentation/
â”‚   â””â”€â”€ installation-guide.md
â””â”€â”€ README.md
```

### Implementation Approach

#### IntegrationHub Spoke Structure
```javascript
// Spoke Action: LLM Chat
// sys_hub_action_type_definition
{
    "name": "LeForge LLM Chat",
    "description": "Send a message to LeForge AI and get a response",
    "category": "LeForge",
    "access": "public",
    "inputs": [
        {
            "name": "message",
            "label": "Message",
            "type": "string",
            "mandatory": true
        },
        {
            "name": "system_prompt", 
            "label": "System Prompt",
            "type": "string",
            "mandatory": false
        },
        {
            "name": "max_tokens",
            "label": "Max Tokens",
            "type": "integer",
            "default": 512
        }
    ],
    "outputs": [
        {
            "name": "response",
            "label": "AI Response",
            "type": "string"
        },
        {
            "name": "tokens_used",
            "label": "Tokens Used", 
            "type": "integer"
        },
        {
            "name": "success",
            "label": "Success",
            "type": "boolean"
        }
    ]
}
```

#### REST Message Configuration
```xml
<!-- LeForge_LLM REST Message -->
<REST_Message>
    <name>LeForge_LLM</name>
    <rest_endpoint>https://your-LeForge-instance.com/api/v1</rest_endpoint>
    <authentication_type>basic</authentication_type>
    
    <HTTP_Methods>
        <method name="chat" http_method="POST">
            <endpoint>/chat</endpoint>
            <headers>
                <header name="Content-Type">application/json</header>
                <header name="X-API-Key">${api_key}</header>
            </headers>
            <content>${request_body}</content>
        </method>
        
        <method name="generate" http_method="POST">
            <endpoint>/generate</endpoint>
            <headers>
                <header name="Content-Type">application/json</header>
                <header name="X-API-Key">${api_key}</header>
            </headers>
            <content>${request_body}</content>
        </method>
    </HTTP_Methods>
</REST_Message>
```

#### Action Script Implementation
```javascript
// Action Script for LLM Chat
(function execute(inputs, outputs) {
    var restMessage = new sn_ws.RESTMessageV2('LeForge_LLM', 'chat');
    
    // Get connection alias credentials
    var connectionAlias = inputs.connection_alias || 'LeForge_connection';
    restMessage.setStringParameterNoEscape('api_key', getApiKey(connectionAlias));
    
    // Build request body
    var requestBody = {
        message: inputs.message,
        system_prompt: inputs.system_prompt || '',
        max_tokens: inputs.max_tokens || 512
    };
    restMessage.setRequestBody(JSON.stringify(requestBody));
    
    var response = restMessage.execute();
    var httpStatus = response.getStatusCode();
    var responseBody = response.getBody();
    
    if (httpStatus == 200) {
        var result = JSON.parse(responseBody);
        outputs.response = result.response;
        outputs.tokens_used = result.tokens_used;
        outputs.success = true;
    } else {
        outputs.success = false;
        outputs.error_message = responseBody;
    }
    
})(inputs, outputs);

function getApiKey(aliasName) {
    var gr = new GlideRecord('sys_alias');
    gr.addQuery('name', aliasName);
    gr.query();
    if (gr.next()) {
        return gr.getValue('api_key');
    }
    return '';
}
```

### Connection Alias for Credentials
```xml
<!-- LeForge_connection alias -->
<sys_alias>
    <name>LeForge_connection</name>
    <type>connection</type>
    <configuration>
        <endpoint>https://your-LeForge-instance.com/api/v1</endpoint>
        <auth_type>api_key</auth_type>
        <api_key_header>X-API-Key</api_key_header>
    </configuration>
</sys_alias>
```

### User Experience in ServiceNow
1. Import Update Set containing the LeForge Spoke
2. Configure Connection Alias with API endpoint and credentials
3. LeForge actions appear in Flow Designer
4. Build flows using drag-and-drop actions
5. Use in Service Catalog, Incident Management, HR workflows, etc.

### Key Features for ServiceNow
- **Flow Designer**: Native low-code flow building
- **IntegrationHub**: Enterprise integration platform
- **Connection Aliases**: Secure, reusable credentials
- **Subflows**: Reusable action sequences
- **Service Catalog**: Self-service automation
- **Virtual Agent**: AI chatbot integration potential

### Use Cases in ServiceNow
| Use Case | LeForge Service | ServiceNow Application |
|----------|-------------------|------------------------|
| Auto-classify incidents | LLM Service | ITSM |
| Generate KB articles | LLM Service | Knowledge Management |
| Encrypt sensitive data | Crypto Service | Security Operations |
| Calculate SLA metrics | Formula Engine | Service Level Management |
| Process attachments | File Service | Any module with attachments |

### OpenAPI Generator Script
Create a script to generate platform-specific OpenAPI files from our base specs:

```python
# scripts/generate-openapi.py
"""
Generate platform-optimized OpenAPI specifications from forgehook.json
"""

def generate_nintex_swagger(plugin_path, output_path):
    """Generate Nintex-compatible Swagger 2.0"""
    pass

def generate_power_automate_connector(plugin_path, output_path):
    """Generate Power Automate connector package"""
    pass

def generate_n8n_node_skeleton(plugin_path, output_path):
    """Generate n8n node TypeScript skeleton"""
    pass
```

### Common Features to Expose

For each plugin, expose these as actions/operations:

#### LLM Service
| Action | Description |
|--------|-------------|
| Chat | Send message, get AI response |
| Generate Text | Complete/generate text |
| Summarize | Summarize documents |
| Classify | Categorize text |
| Extract Entities | Extract structured data |
| Generate Embeddings | Create vector embeddings |

#### Formula Engine
| Action | Description |
|--------|-------------|
| Evaluate Formula | Calculate Excel formula |
| Batch Calculate | Process multiple formulas |
| Validate Formula | Check formula syntax |
| List Functions | Get available functions |

#### Streaming File Service
| Action | Description |
|--------|-------------|
| Upload File | Upload large files |
| Download File | Stream download |
| Process CSV | Parse/transform CSV |
| Process Excel | Read/write Excel |
| Convert Format | Convert between formats |

#### Crypto Service
| Action | Description |
|--------|-------------|
| Encrypt Data | Encrypt with AES/RSA |
| Decrypt Data | Decrypt data |
| Hash Data | Generate hash (SHA256, etc.) |
| Sign Data | Create digital signature |
| Verify Signature | Verify digital signature |
| Generate Keys | Create key pairs |

---

## Implementation Roadmap

### Phase 1: Foundation (Week 1-2)
- [x] Create OpenAPI 2.0 specs for all plugins
- [x] Create OpenAPI 3.0 specs for all plugins
- [x] Build OpenAPI generator script
- [ ] Create icons/branding for each plugin

### Phase 2: Microsoft & Nintex (Week 3-4)
- [x] Power Automate custom connectors (4 plugins)
- [x] Nintex Workflow Cloud Xtensions (4 plugins)
- [x] Nintex K2 Swagger + SmartObject templates
- [ ] Testing and documentation

### Phase 3: n8n (Week 5-6)
- [x] n8n node package structure
- [x] Implement all nodes with credentials
- [ ] Test with n8n self-hosted
- [ ] Publish to npm
- [ ] Submit to n8n Community Nodes

### Phase 4: Low-Code Platforms (Week 7-8)
- [ ] OutSystems Forge components
- [ ] Mendix Marketplace modules
- [ ] Integration testing
- [ ] Documentation and examples

### Phase 5: Enterprise Platforms (Week 9-10)
- [ ] Salesforce External Services + Apex package
- [ ] ServiceNow IntegrationHub Spoke
- [ ] Named Credentials / Connection Alias setup
- [ ] Testing in sandbox environments

### Phase 6: Certification & Publishing (Week 11-12)
- [ ] Power Automate connector certification
- [ ] Salesforce AppExchange listing
- [ ] ServiceNow Store submission
- [ ] OutSystems Forge publishing
- [ ] Mendix Marketplace publishing
- [ ] Marketing materials

---

## Recommended Priority

Based on market reach and implementation effort:

1. **Power Automate** - Largest user base, easy OpenAPI import âœ… In Progress
2. **Nintex Workflow Cloud** - Direct competitor, OpenAPI-based âœ… In Progress
3. **n8n** - Growing open-source community, good visibility âœ… In Progress
4. **Salesforce** - Massive enterprise market, Flow Builder adoption ğŸ†•
5. **ServiceNow** - Enterprise ITSM leader, IntegrationHub growing ğŸ†•
6. **OutSystems** - Enterprise low-code, REST-friendly
7. **Nintex K2** - Legacy but still used, more complex âœ… In Progress
8. **Mendix** - Requires most custom work

---

## 9. Integration Asset Distribution

### Strategy: Registry API Endpoint

Rather than bundling integration assets or requiring manual downloads, the LeForge Registry exposes an API endpoint that generates and serves platform-specific integration packages on-demand.

### API Design

```
GET /api/v1/plugins/{plugin}/integrations/{platform}
GET /api/v1/plugins/{plugin}/integrations/{platform}/{asset}
```

#### Endpoints

| Endpoint | Description | Response |
|----------|-------------|----------|
| `GET /plugins/llm-service/integrations` | List available platforms | JSON array of platforms |
| `GET /plugins/llm-service/integrations/nintex-cloud` | Get Nintex Cloud package | ZIP with swagger + readme |
| `GET /plugins/llm-service/integrations/nintex-cloud/swagger.json` | Swagger file only | JSON |
| `GET /plugins/llm-service/integrations/nintex-k2` | Get K2 package | ZIP with swagger + SmartObjects |
| `GET /plugins/llm-service/integrations/salesforce` | Salesforce package | ZIP with OpenAPI + Apex classes |
| `GET /plugins/llm-service/integrations/servicenow` | ServiceNow spoke | ZIP with spoke XML + scripts |

#### Query Parameters

| Parameter | Description | Example |
|-----------|-------------|---------|
| `baseUrl` | Override default API base URL | `?baseUrl=https://api.mycompany.com` |
| `version` | Plugin version (default: latest) | `?version=2.1.0` |
| `format` | Response format: `zip`, `json`, `yaml` | `?format=json` |
| `auth` | Auth type hint for spec | `?auth=oauth2` |

### Example Requests

```bash
# Download Nintex Cloud Xtension package
curl -o llm-service-nintex.zip \
  "https://registry.LeForge.io/api/v1/plugins/llm-service/integrations/nintex-cloud?baseUrl=https://LeForge.mycompany.com"

# Get just the Swagger file
curl "https://registry.LeForge.io/api/v1/plugins/llm-service/integrations/nintex-cloud/swagger.json"

# Download K2 SmartObject templates
curl -o llm-service-k2.zip \
  "https://registry.LeForge.io/api/v1/plugins/llm-service/integrations/nintex-k2"

# Get Salesforce Apex classes
curl -o llm-salesforce.zip \
  "https://registry.LeForge.io/api/v1/plugins/llm-service/integrations/salesforce"
```

### Response Structure

#### List Integrations
```json
{
  "plugin": "llm-service",
  "version": "2.0.0",
  "integrations": [
    {
      "platform": "nintex-cloud",
      "name": "Nintex Workflow Cloud",
      "format": "OpenAPI 2.0 (Swagger)",
      "assets": ["swagger.json", "icon.png", "README.md"]
    },
    {
      "platform": "nintex-k2",
      "name": "Nintex K2",
      "format": "Swagger 2.0 + SmartObjects",
      "assets": ["swagger.json", "smartobjects/", "README.md"]
    },
    {
      "platform": "salesforce",
      "name": "Salesforce",
      "format": "OpenAPI 3.0 + Apex",
      "assets": ["openapi.yaml", "apex/", "package.xml", "README.md"]
    },
    {
      "platform": "servicenow",
      "name": "ServiceNow",
      "format": "IntegrationHub Spoke",
      "assets": ["spoke/", "rest_messages/", "README.md"]
    },
    {
      "platform": "power-automate",
      "name": "Power Automate",
      "format": "Custom Connector",
      "assets": ["apiDefinition.swagger.json", "apiProperties.json", "icon.png"]
    }
  ]
}
```

#### ZIP Package Contents

**Nintex Cloud (`nintex-cloud.zip`):**
```
llm-service-nintex-cloud/
â”œâ”€â”€ llm-service.swagger.json
â”œâ”€â”€ icon.png
â”œâ”€â”€ README.md
â””â”€â”€ INSTALLATION.md
```

**Nintex K2 (`nintex-k2.zip`):**
```
llm-service-k2/
â”œâ”€â”€ swagger/
â”‚   â””â”€â”€ llm-service.swagger.json
â”œâ”€â”€ smartobjects/
â”‚   â”œâ”€â”€ LlmChat.xml
â”‚   â”œâ”€â”€ LlmClassify.xml
â”‚   â””â”€â”€ LlmSummarize.xml
â”œâ”€â”€ README.md
â””â”€â”€ INSTALLATION.md
```

**Salesforce (`salesforce.zip`):**
```
llm-service-salesforce/
â”œâ”€â”€ external-services/
â”‚   â””â”€â”€ LeForge_LLM.yaml
â”œâ”€â”€ apex/
â”‚   â”œâ”€â”€ classes/
â”‚   â”‚   â”œâ”€â”€ LeForgeLLMService.cls
â”‚   â”‚   â””â”€â”€ LeForgeLLMService.cls-meta.xml
â”‚   â””â”€â”€ namedCredentials/
â”‚       â””â”€â”€ LeForge_API.namedCredential-meta.xml
â”œâ”€â”€ package.xml
â”œâ”€â”€ README.md
â””â”€â”€ INSTALLATION.md
```

### Implementation Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LeForge Registry                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  GET /plugins/{plugin}/integrations/{platform}               â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚         Integration Generator            â”‚               â”‚
â”‚  â”‚                                          â”‚               â”‚
â”‚  â”‚  1. Load forgehook.json                  â”‚               â”‚
â”‚  â”‚  2. Apply baseUrl override               â”‚               â”‚
â”‚  â”‚  3. Generate platform-specific assets    â”‚               â”‚
â”‚  â”‚  4. Package as ZIP or return single file â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚              Asset Cache                  â”‚               â”‚
â”‚  â”‚  (Redis/filesystem, 1hr TTL)             â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CLI Integration

The `LeForge` CLI can also fetch integration assets:

```bash
# Download integration package
LeForge integrations download llm-service --platform nintex-cloud --output ./

# List available integrations
LeForge integrations list llm-service

# Generate with custom base URL
LeForge integrations download crypto-service --platform salesforce \
  --base-url https://LeForge.mycompany.com
```

### Air-Gapped / Offline Distribution

For environments without internet access (air-gapped networks), integration assets are available through multiple offline channels:

#### Option 1: Bundled in Plugin Docker Images

Each plugin Docker image includes pre-generated integration assets at `/integrations/`:

```
/integrations/
â”œâ”€â”€ nintex-cloud/
â”‚   â”œâ”€â”€ swagger.json
â”‚   â”œâ”€â”€ icon.png
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ nintex-k2/
â”‚   â”œâ”€â”€ swagger.json
â”‚   â”œâ”€â”€ smartobjects/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ salesforce/
â”‚   â”œâ”€â”€ openapi.yaml
â”‚   â”œâ”€â”€ apex/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ servicenow/
â”‚   â”œâ”€â”€ spoke/
â”‚   â””â”€â”€ README.md
â””â”€â”€ power-automate/
    â”œâ”€â”€ apiDefinition.swagger.json
    â””â”€â”€ apiProperties.json
```

**Extract from running container:**
```bash
# Copy integration assets from running container
docker cp LeForge-llm-service:/integrations ./llm-service-integrations

# Or from image directly
docker run --rm -v $(pwd)/output:/out LeForge/llm-service:2.0.0 \
  cp -r /integrations /out/
```

**Air-Gapped K2 5.9 Workflow:**
```bash
# 1. On internet-connected machine, pull and save image
docker pull LeForge/llm-service:2.0.0
docker save LeForge/llm-service:2.0.0 -o llm-service.tar

# 2. Transfer llm-service.tar to air-gapped network (USB, etc.)

# 3. On air-gapped network, load image
docker load -i llm-service.tar

# 4. Extract K2 integration assets
docker run --rm -v /path/to/output:/out LeForge/llm-service:2.0.0 \
  cp -r /integrations/nintex-k2 /out/

# 5. Import swagger.json into K2 REST Service Broker
# 6. Import SmartObjects from smartobjects/ folder
```

#### Option 2: GitHub Release Artifacts

Each LeForge release includes downloadable integration bundles:

```
LeForge-v2.0.0-integrations.zip
â”œâ”€â”€ llm-service/
â”‚   â”œâ”€â”€ nintex-cloud.zip
â”‚   â”œâ”€â”€ nintex-k2.zip
â”‚   â”œâ”€â”€ salesforce.zip
â”‚   â”œâ”€â”€ servicenow.zip
â”‚   â””â”€â”€ power-automate.zip
â”œâ”€â”€ crypto-service/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ formula-engine/
â”‚   â””â”€â”€ ...
â””â”€â”€ streaming-file-service/
    â””â”€â”€ ...
```

Download once, transfer to air-gapped network, extract as needed.

#### Option 3: LeForge Installer Bundle

The enterprise LeForge installer includes all integration assets:

```
LeForge-enterprise-2.0.0/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ llm-service.tar
â”‚   â”œâ”€â”€ crypto-service.tar
â”‚   â””â”€â”€ ...
â”œâ”€â”€ integrations/           # Pre-extracted for convenience
â”‚   â”œâ”€â”€ nintex-cloud/
â”‚   â”œâ”€â”€ nintex-k2/
â”‚   â”œâ”€â”€ salesforce/
â”‚   â””â”€â”€ ...
â””â”€â”€ docs/
    â””â”€â”€ air-gapped-install.md
```

#### Air-Gapped Customization

Since air-gapped assets are pre-generated, the `baseUrl` needs manual editing:

**Swagger files (Nintex Cloud/K2):**
```json
{
  "host": "LeForge.internal.company.com",
  "basePath": "/api/v1",
  "schemes": ["https"]
}
```

**Salesforce Named Credential:**
Edit `LeForge_API.namedCredential-meta.xml`:
```xml
<endpoint>https://LeForge.internal.company.com</endpoint>
```

**ServiceNow Connection Alias:**
Update `connection_alias.xml` or configure in ServiceNow UI after import.

#### Build-Time Integration Generation

For CI/CD pipelines in air-gapped environments, run the generator during build:

```bash
# In your build pipeline (before air-gap)
python scripts/generate-integrations.py \
  --plugin llm-service \
  --platform nintex-k2 \
  --base-url https://LeForge.internal.corp \
  --output ./release/integrations/

# Bundle output with your deployment artifacts
```

### Customer Workflow

#### Nintex Workflow Cloud
1. **Admin** visits LeForge registry or uses CLI
2. Downloads `llm-service-nintex-cloud.zip`
3. Extracts and uploads `swagger.json` to Nintex Xtensions
4. Configures API key
5. Actions available in workflow designer

#### Nintex K2 5.9 (Connected)
1. **Admin** downloads `llm-service-k2.zip`
2. Imports swagger via K2 REST Service Broker
3. Imports SmartObject templates from `smartobjects/`
4. Configures service instance with API key
5. SmartObjects available in K2 Designer

#### Nintex K2 5.9 (Air-Gapped)
1. **Admin** extracts assets from Docker image or installer bundle
2. Edits `swagger.json` to set internal `host` URL
3. Imports swagger via K2 REST Service Broker
4. Imports SmartObject templates from `smartobjects/`
5. Configures service instance with API key
6. SmartObjects available in K2 Designer

#### Salesforce
1. **Admin** downloads `llm-service-salesforce.zip`
2. Deploys via Salesforce CLI: `sf project deploy start --source-dir llm-service-salesforce/`
3. Configures Named Credential with OAuth/API key
4. Invocable Actions appear in Flow Builder

#### ServiceNow
1. **Admin** downloads `llm-service-servicenow.zip`
2. Imports spoke via Update Set or Studio
3. Configures Connection Alias
4. Actions available in Flow Designer

---

## Next Steps

1. **Approve this proposal** and prioritize platforms
2. **Set up integration folder structure** in repository
3. **Begin with OpenAPI generation** (foundation for most platforms)
4. **Create first Power Automate connector** as proof of concept
5. **Implement registry API endpoint** for asset distribution
6. **Iterate based on feedback**

---

## Questions to Resolve

1. Will plugins be self-hosted or SaaS? (Affects connector URLs)
2. What authentication method is preferred? (API Key recommended)
3. Do we want certified/published connectors or private only?
4. What's the branding/naming convention? (LeForge vs custom?)
5. ~~How do customers get integration assets?~~ âœ… Registry API endpoint
